{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-12T17:02:18.120437Z","iopub.execute_input":"2021-06-12T17:02:18.120767Z","iopub.status.idle":"2021-06-12T17:02:18.129683Z","shell.execute_reply.started":"2021-06-12T17:02:18.120739Z","shell.execute_reply":"2021-06-12T17:02:18.128729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***In the next cell:\n1-reading train data file and store it in a variable named 'df'\n2-printing the first rows of the dataframe\n3-checking the summ of null values in each column***","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ndf.head()\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-12T17:02:18.131492Z","iopub.execute_input":"2021-06-12T17:02:18.131921Z","iopub.status.idle":"2021-06-12T17:02:18.158658Z","shell.execute_reply.started":"2021-06-12T17:02:18.131877Z","shell.execute_reply":"2021-06-12T17:02:18.157706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***In the next cell:***\n1. read test data file and store it in a variable named 'test'\n1. filling the null values in the age column with median of the ages.\n1. filling the null values in the fare column.\n1. replacing each male gender value with a value of 1 and female value to a value of 0.\n1. storing passengers id in a variable so we can use it in the submission of the output later.\n1. drop all unsused feature so we having same features as the training set.\n1. printing the first rows of the dataframe**","metadata":{}},{"cell_type":"code","source":"test= pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest['Age'].fillna(value=df['Age'].median(), inplace = True)\ntest[\"Fare\"].fillna( method ='pad', inplace = True)\ntest=test.replace(to_replace =\"male\", value = 1)\ntest=test.replace(to_replace =\"female\", value = 0)\nPassengerId=test['PassengerId']\ntest=test.drop(['Name','Cabin','Embarked','Ticket','PassengerId'],axis=1)\ntest.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-12T17:02:18.160329Z","iopub.execute_input":"2021-06-12T17:02:18.160613Z","iopub.status.idle":"2021-06-12T17:02:18.189107Z","shell.execute_reply.started":"2021-06-12T17:02:18.160586Z","shell.execute_reply":"2021-06-12T17:02:18.188016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**In the next cell:**\n1. checking the sum of null values in each column of the test dataset making sure each of them is zero.","metadata":{}},{"cell_type":"code","source":"test.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-12T17:02:18.190699Z","iopub.execute_input":"2021-06-12T17:02:18.191136Z","iopub.status.idle":"2021-06-12T17:02:18.197975Z","shell.execute_reply.started":"2021-06-12T17:02:18.191094Z","shell.execute_reply":"2021-06-12T17:02:18.197181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**In the next cell:**\n1. filling the null values in the age column with median of the ages.\n1. replacing each male gender value with a value of 1 and female value to a value of 0.\n1. printing the first rows of the dataframe","metadata":{}},{"cell_type":"code","source":"df['Age'].fillna(value=df['Age'].median(), inplace = True)\ndf=df.replace(to_replace =\"male\", value = 1)\ndf=df.replace(to_replace =\"female\", value = 0)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-12T17:02:18.199011Z","iopub.execute_input":"2021-06-12T17:02:18.199418Z","iopub.status.idle":"2021-06-12T17:02:18.229354Z","shell.execute_reply.started":"2021-06-12T17:02:18.199389Z","shell.execute_reply":"2021-06-12T17:02:18.228623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**In the next cell:**\n1. checking the sum of null values in each column of the train dataset again making sure each of them is zero.","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-12T17:02:18.230302Z","iopub.execute_input":"2021-06-12T17:02:18.230683Z","iopub.status.idle":"2021-06-12T17:02:18.240291Z","shell.execute_reply.started":"2021-06-12T17:02:18.230655Z","shell.execute_reply":"2021-06-12T17:02:18.239122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**In the next cell:**\n1. storing our target in a variable named y to use iut later in fitting our model.\n1. speciifying our feature and save them in an array to use in the next step.\n1. create a variable X with dataframe with only the specified features.\n1. splitting the train set into train data and values so we can use it in evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ny = df.Survived\nfeatures = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\nX = df[features]\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T17:02:18.242017Z","iopub.execute_input":"2021-06-12T17:02:18.242458Z","iopub.status.idle":"2021-06-12T17:02:18.255975Z","shell.execute_reply.started":"2021-06-12T17:02:18.242412Z","shell.execute_reply":"2021-06-12T17:02:18.254911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**In the next cell after the imports:**\n1. creating our model where we used decision tree.\n1. fitting the model with the training X and y created early.\n1. storing our prediction from the training set into a variable to use it later in the evaluation.\n1. Use classification report evaluation technique .\n1. print the report.\n1. Use accuracy score evaluation and print the report.","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nmodel = DecisionTreeRegressor(random_state=1)\nmodel.fit(train_X, train_y)\npredicted = model.predict(val_X).astype(int)\nreport = classification_report(val_y, predicted)\nprint(report)\nprint(accuracy_score(val_y, predicted))","metadata":{"execution":{"iopub.status.busy":"2021-06-12T17:02:18.25821Z","iopub.execute_input":"2021-06-12T17:02:18.258608Z","iopub.status.idle":"2021-06-12T17:02:18.281216Z","shell.execute_reply.started":"2021-06-12T17:02:18.258571Z","shell.execute_reply":"2021-06-12T17:02:18.280078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**In the next cell:**\n1. fitting the model again with the whole training set without splitting it.\n1. storing our final prediction from the test set into a variable to use it later in the sumbmission.\n1. print the predictions.","metadata":{}},{"cell_type":"code","source":"model.fit(X, y)\npredictions=model.predict(test).astype(int)\nprint(predictions)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T17:02:18.282637Z","iopub.execute_input":"2021-06-12T17:02:18.283124Z","iopub.status.idle":"2021-06-12T17:02:18.296534Z","shell.execute_reply.started":"2021-06-12T17:02:18.28308Z","shell.execute_reply":"2021-06-12T17:02:18.29536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\noutput = pd.DataFrame({'PassengerId': PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2021-06-12T17:02:18.297974Z","iopub.execute_input":"2021-06-12T17:02:18.298276Z","iopub.status.idle":"2021-06-12T17:02:18.308019Z","shell.execute_reply.started":"2021-06-12T17:02:18.298247Z","shell.execute_reply":"2021-06-12T17:02:18.307154Z"},"trusted":true},"execution_count":null,"outputs":[]}]}